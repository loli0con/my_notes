# Hadoop 运行环境搭建

## 环境规划

### 使用软件
1. Vmware
2. CentOS7: CentOS-7-x86_64-Minimal-2009.iso
3. JDK8: jdk-8u201-linux-x64.tar.gz
4. Hadoop3: hadoop-3.1.3.tar.gz

### 网络规划
* 子网IP: 192.168.10.0
* 子网掩码: 255.255.255.0
* 网关IP: 192.168.10.2

### 集群部署规划
|节点|hadoop102|hadoop103|hadoop104|
|---|---|---|---|
|主机名|hadoop102|hadoop103|hadoop104|
|IP地址|192.168.10.102|192.168.10.103|192.168.10.104|
|HDFS|**NameNode**<br>DataNode|DataNode|**SecondaryNameNode**<br>DataNode|
|YARN|NodeManager|**ResourceManager**<br>NodeManager|NodeManager|

注意点:
1. NameNode和SecondaryNameNode不要安装在同一台服务器
2. ResourceManager很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上




## 模版机制作 - hadoop100
```sh
# 修改主机名称
vi /etc/hostname
###### /etc/hostname ######
hadoop100
###### /etc/hostname ######


# 修改IP地址
vi /etc/sysconfig/network-scripts/ifcfg-ens33
###### /etc/sysconfig/network-scripts/ifcfg-ens33 ######
DEVICE=ens33
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
NAME="ens33"
IPADDR=192.168.10.102 # 视情况修改，IP地址
PREFIX=24 # 视情况修改，子网掩码
GATEWAY=192.168.10.2 # 视情况修改，网关地址
DNS1=192.168.10.2 # 视情况修改，DNS服务器地址
###### /etc/sysconfig/network-scripts/ifcfg-ens33 ######


# 配置主机名称映射 hosts 文件
vim /etc/hosts
###### /etc/hosts ######
192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108
###### /etc/hosts ######


# 安装 epel-release
yum install -y epel-release


# 安装工具
yum install -y net-tools
yum install -y vim


# 关闭防火墙
systemctl stop firewalld
systemctl disable firewalld.service


# 创建 hadoop 用户，并修改 hadoop 用户的密码
useradd hadoop
passwd hadoop


# 配置 hadoop 用户具有 root 权限
vim /etc/sudoers
# 在%wheel 这行下面添加一行
###### /etc/sudoers内容 ######
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
## Allows people in group wheel to run all commands
%wheel ALL=(ALL) ALL
hadoop ALL=(ALL) NOPASSWD:ALL
###### /etc/sudoers ######


# 在 /opt 目录下创建文件夹，并修改所属主和所属组
mkdir /opt/module
mkdir /opt/software
chown hadoop:hadoop /opt/module
chown hadoop:hadoop /opt/software


# 在 /opt/module 目录下安装 JDK
tar -zxvf jdk-8u201-linux-x64.tar.gz -C /opt/module/
# 在 /opt/software 目录下安装 Hadoop
tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/


# 配置 JDK 环境变量
sudo vim /etc/profile.d/jh_env.sh
# 添加如下内容
###### /etc/profile.d/jh_env.sh ######
# JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_201
export PATH=$PATH:$JAVA_HOME/bin
###### /etc/profile.d/jh_env.sh ######


# 将 Hadoop 添加到环境变量
## 在jh_env.sh文件末尾添加如下内容
#HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

### 克隆机制作 - hadoop102&hadoop103&hadoop104
以**hadoop102**为例，修改其IP和主机名等配置。

#### 修改静态 IP
```bash
vim /etc/sysconfig/network-scripts/ifcfg-ens33
###### /etc/sysconfig/network-scripts/ifcfg-ens33 ######
DEVICE=ens33
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
NAME="ens33"
IPADDR=192.168.10.102 # 视情况修改，IP地址
PREFIX=24 # 视情况修改，子网掩码
GATEWAY=192.168.10.2 # 视情况修改，网关地址
DNS1=192.168.10.2 # 视情况修改，DNS服务器地址
###### /etc/sysconfig/network-scripts/ifcfg-ens33 ######
```

#### 修改主机名
```bash
# 修改主机名称
vim /etc/hostname
###### /etc/hostname ######
hadoop102
###### /etc/hostname ######
```


### SSH 无密登录配置

#### 免密登录原理
![运行环境搭建+20221110103144](https://raw.githubusercontent.com/loli0con/picgo/master/images/%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2B20221110103144.png%2B2022-11-10-10-31-46)

#### 生成公钥和私钥
```bash
ssh-keygen -t rsa
# 然后敲(三个回车)，就会生成两个文件 id_rsa(私钥)、id_rsa.pub(公钥)
```

#### .ssh 文件夹下(~/.ssh)的文件功能解释
* known_hosts: 记录 ssh 访问过计算机的公钥(public key)
* id_rsa: 生成的私钥
* .id_rsapub: 生成的公钥
* authorized_keys: 存放授权过的无密登录服务器公钥

#### 将公钥拷贝到要免密登录的目标机器上
```bash
ssh-copy-id hadoop102
ssh-copy-id hadoop103
ssh-copy-id hadoop104
# 备注hadoop102、hadoop103、hadoop104需要启动并正常联网
```



## Hadoop程序描述

### 重要目录
1. bin目录: 存放对 Hadoop 相关服务(hdfs，yarn，mapred)进行操作的脚本
2. etc目录: Hadoop 的配置文件目录，存放 Hadoop 的配置文件
3. lib目录: 存放 Hadoop 的本地库(对数据进行压缩解压缩功能)
4. sbin目录: 存放启动或停止 Hadoop 相关服务的脚本
5. share目录: 存放 Hadoop 的依赖 jar 包、文档、和官方案例

### 配置文件
Hadoop 配置文件分两类: 默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。

#### 默认配置文件
|要获取的默认文件|文件存放在 Hadoop 的 jar 包中的位置
|---|---|
|core-default.xml|hadoop-common-3.1.3.jar/core-default.xml|
|hdfs-default.xml|hadoop-hdfs-3.1.3.jar/hdfs-default.xml|
|yarn-default.xml|hadoop-yarn-common-3.1.3.jar/yarn-default.xml|
|mapred-default.xml|hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml|

#### 自定义配置文件
core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在 $HADOOP_HOME/etc/hadoop 这个路径上，用户可以根据项目需求重新进行修改配置。

### 常用端口号
|端口名称|端口号|
|---|---|
|NameNode 内部通信端口|**8020**/9000/9820|
|NameNode HTTP UI|**9870**|
|MapReduce 查看执行任务端口|8088|
|历史服务器通信端口|19888|


## Hadoop配置

### 便捷脚本

#### 集群分发脚本
xsync
```bash
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]; then
    echo Not Enough Arguement!
    exit 1
if

#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
    echo ==================== $host ====================
    #3. 遍历所有目录，挨个发送

    for file in $@
    do
        #4. 判断文件是否存在
        if [ -e $file ]
            then
                #5. 获取父目录
                pdir=$(cd -P $(dirname $file); pwd)

                #6. 获取当前文件的名称
                fname=$(basename $file)
                ssh $host "mkdir -p $pdir"
                rsync -av $pdir/$fname $host:$pdir
            else
                echo $file does not exists!
        fi
    done
done
```

#### 集群启停脚本
myhadoop.sh start/stop
```bash
#!/bin/bash
if [ $# -lt 1 ]
then
    echo "No Args Input..."
    exit 1
fi

case $1 in
"start")
    echo " =================== 启动 hadoop 集群 ==================="

    echo " --------------- 启动 hdfs ---------------"
    ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh"
    echo " --------------- 启动 yarn ---------------"
    ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh"
    echo " --------------- 启动 historyserver ---------------"
    ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"
;;
"stop")
    echo " =================== 关闭 hadoop 集群 ==================="
    
    echo " --------------- 关闭 historyserver ---------------"
    ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"
    echo " --------------- 关闭 yarn ---------------"
    ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"
    echo " --------------- 关闭 hdfs ---------------"
    ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"
;;
*)
    echo "Input Args Error..."
;;
esac
```

### 集群配置

#### core-site.xml
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 指定 NameNode 的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop102:8020</value>
    </property>

    <!-- 指定 hadoop 数据的存储目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
    </property>

    <!-- 配置 HDFS 网页登录使用的静态用户为 hadoop -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>hadoop</value>
    </property>
</configuration>
```

#### hdfs-site.xml
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- nn web端访问地址-->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop102:9870</value>
    </property>
    <!-- 2nn web 端访问地址-->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop104:9868</value>
    </property>
</configuration>
```

#### yarn-site.xml
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 指定 MR 走 shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>

    <!-- 指定 ResourceManager 的地址-->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop103</value>
    </property>
    
    <!-- 环境变量的继承 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
   </property>
</configuration>
```

#### mapred-site.xml
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 指定 MapReduce 程序运行在 Yarn 上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
   </property>
</configuration>
```

#### workers
```bash
vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
###### /opt/module/hadoop-3.1.3/etc/hadoop/workers ######
hadoop102
hadoop103
hadoop104
###### /opt/module/hadoop-3.1.3/etc/hadoop/workers ######
```

### NameNode格式化
如果集群是第一次启动，需要在格式化 NameNode。格式化 NameNode，会产生新的集群 id，导致 NameNode 和 DataNode 的集群 id 不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化 NameNode 的话，一定要先停止 namenode 和 datanode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化。

```bash
# NameNode所在节点
hdfs namenode -format
```

### 启动HDFS
```bash
# NameNode所在节点
sbin/start-dfs.sh
```

### 启动 YARN
```bash
# ResourceManager所在节点
sbin/start-yarn.sh
```

### 集群信息查看
* Web 端查看 HDFS 的 NameNode
  1. 浏览器中输入: http://hadoop102:9870
  2. 查看 HDFS 上存储的数据信息
* Web 端查看 YARN 的 ResourceManager
  1. 浏览器中输入: http://hadoop103:8088
  2. 查看 YARN 上运行的 Job 信息





## 日志聚集

### 定义
应用运行完成以后，将程序运行日志信息上传到 HDFS 系统上。可以方便的查看到程序运行详情，方便开发调试。

![运行环境搭建+20221110150436](https://raw.githubusercontent.com/loli0con/picgo/master/images/%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2B20221110150436.png%2B2022-11-10-15-04-36)

### 配置

#### mapred-site.xml
```xml
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop102:10020</value>
</property>
<!-- 历史服务器 web 端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop102:19888</value>
</property>
```

#### yarn-site.xml
```xml
<!-- 开启日志聚集功能 -->
<property>
    <name>yarn.log-aggregation-enable</name>
   <value>true</value>
</property>

<!-- 设置日志聚集服务器地址 -->
<property>
    <name>yarn.log.server.url</name>
    <value>http://hadoop102:19888/jobhistory/logs</value>
</property>

<!-- 设置日志保留时间为 7 天 -->
<property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>604800</value>
</property>
```

### 启动
```bash
# 在ResourceManager所在节点执行，重启NodeManager 、ResourceManage 和 HistoryServer
sbin/stop-yarn.sh
mapred --daemon stop historyserver
start-yarn.sh
mapred --daemon start historyserver
```

### 查看
http://hadoop102:19888/jobhistory





## 集群时间同步
如果服务器在公网环境(能连接外网)，可以不采用集群时间同步，因为服务器会定期和公网时间进行校准;如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，导致集群执行任务时间不同步。

todo