# Hadoop 运行环境搭建

## 环境规划

### 使用软件
1. Vmware
2. CentOS7: CentOS-7-x86_64-Minimal-2009.iso
3. JDK8: jdk-8u201-linux-x64.tar.gz
4. Hadoop3: hadoop-3.1.3.tar.gz

### 网络规划
* 子网IP: 192.168.10.0
* 子网掩码: 255.255.255.0
* 网关IP: 192.168.10.2

### 集群部署规划
|主机名|IP地址|HDFS|YARN|
|---|---|---|---|
|hadoop102|192.168.10.102|**NameNode**<br>DataNode|NodeManager|
|hadoop103|192.168.10.103|DataNode|**ResourceManager**<br>NodeManager|
|hadoop104|192.168.10.104|**SecondaryNameNode**<br>DataNode|NodeManager|
|hadoopXXX|192.168.10.XXX|DataNode|NodeManager|

注意点:
1. NameNode和SecondaryNameNode不要安装在同一台服务器
2. ResourceManager很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上




## 模版机制作 - hadoop100
```sh
# 修改主机名称
vi /etc/hostname
###### /etc/hostname ######
hadoop100
###### /etc/hostname ######


# 修改IP地址
vi /etc/sysconfig/network-scripts/ifcfg-ens33
###### /etc/sysconfig/network-scripts/ifcfg-ens33 ######
DEVICE=ens33
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
NAME="ens33"
IPADDR=192.168.10.100 # 视情况修改，IP地址
PREFIX=24 # 视情况修改，子网掩码
GATEWAY=192.168.10.2 # 视情况修改，网关地址
DNS1=192.168.10.2 # 视情况修改，DNS服务器地址
###### /etc/sysconfig/network-scripts/ifcfg-ens33 ######


# 配置主机名称映射 hosts 文件（以此类推）
vi /etc/hosts
###### /etc/hosts ######
192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108
192.168.10.109 hadoop109
###### /etc/hosts ######


# 安装 epel-release & 安装工具 —— 可选项
yum install -y epel-release
yum install -y net-tools
yum install -y vim # 如不安装vim，后续的命令可以使用vi代替vim


# 关闭防火墙
systemctl stop firewalld
systemctl disable firewalld.service


# 创建 hadoop 用户，并修改 hadoop 用户的密码
useradd hadoop
passwd hadoop


# 配置 hadoop 用户具有 root 权限
vim /etc/sudoers
# 在%wheel 这行下面添加一行
###### /etc/sudoers内容 ######
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
## Allows people in group wheel to run all commands
%wheel ALL=(ALL) ALL
hadoop ALL=(ALL) NOPASSWD:ALL
###### /etc/sudoers ######


# 在 /opt 目录下创建文件夹，并修改所属主和所属组
mkdir /opt/module
mkdir /opt/software
chown -R hadoop:hadoop /opt/module
chown -R hadoop:hadoop /opt/software


# 在 /opt/module 目录下安装 JDK
tar -zxvf jdk-8u201-linux-x64.tar.gz -C /opt/module/
# 在 /opt/software 目录下安装 Hadoop
tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/


# 环境变量配置
sudo vim /etc/profile.d/jh_env.sh
###### /etc/profile.d/jh_env.sh ######
# JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_201
export PATH=$PATH:$JAVA_HOME/bin
# HADOOP_HOME（HADOOP环境变量）
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
###### /etc/profile.d/jh_env.sh ######
```




## 克隆机制作 - hadoop102&hadoop103&hadoop104
以**hadoop102**为例，修改其IP和主机名等配置。

### 修改静态 IP
```bash
vim /etc/sysconfig/network-scripts/ifcfg-ens33
###### /etc/sysconfig/network-scripts/ifcfg-ens33 ######
DEVICE=ens33
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
NAME="ens33"
IPADDR=192.168.10.102 # 视情况修改，IP地址
PREFIX=24 # 视情况修改，子网掩码
GATEWAY=192.168.10.2 # 视情况修改，网关地址
DNS1=192.168.10.2 # 视情况修改，DNS服务器地址
###### /etc/sysconfig/network-scripts/ifcfg-ens33 ######
```

### 修改主机名
```bash
# 修改主机名称
vim /etc/hostname
###### /etc/hostname ######
hadoop102
###### /etc/hostname ######
```


### SSH 无密登录配置

#### 免密登录原理
![运行环境搭建+20221110103144](https://raw.githubusercontent.com/loli0con/picgo/master/images/%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2B20221110103144.png%2B2022-11-10-10-31-46)

#### 生成公钥和私钥
```bash
ssh-keygen -t rsa
# 然后敲三个回车（可选的配置填写步骤），就会生成两个文件 id_rsa(私钥)、id_rsa.pub(公钥)
```

#### .ssh 文件夹下(~/.ssh)的文件功能解释
* known_hosts: 记录 ssh 访问过计算机的公钥(public key)
* id_rsa: 生成的私钥
* .id_rsapub: 生成的公钥
* authorized_keys: 存放授权过的无密登录服务器公钥

#### 将公钥拷贝到要免密登录的目标机器上
```bash
ssh-copy-id hadoop102
ssh-copy-id hadoop103
ssh-copy-id hadoop104
# 备注hadoop102、hadoop103、hadoop104需要启动并网络连通
```



## Hadoop程序介绍

### 目录结构
1. bin目录: 存放对 Hadoop 相关服务(hdfs，yarn，mapred)进行操作的脚本
2. etc目录: Hadoop 的配置文件目录，存放 Hadoop 的配置文件
3. sbin目录: 存放启动或停止 Hadoop 相关服务的管理脚本，主要包含 HDFS 和 YARN 中各类服务的启动/关闭脚本
4. share目录: 存放 Hadoop 各个模块编译后的 jar 包，以及官方文档和官方案例
5. include目录: 对外提供的变成库头文件(具体动态库和静态库在 lib 目录中)，这些头文件均是用 C++ 定义的，通用常用于 C++ 程序访问 HDFS 或者编写 MapReduce 程序
6. lib目录: 存放 Hadoop 的本地库(对数据进行压缩解压缩功能)，包含了 Hadoop 对外提供的编程动态库和静态库，与 include 目录中的头文件结合使用
7. libexec: 各个服务对用的 shell 配置文件所在的目录，可用于配制日志输出、启动参数(比如 JVM 参数)等基本信息


### 配置文件
Hadoop 配置文件分两类: 默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。

#### 默认配置文件
|要获取的默认文件|文件存放在 Hadoop 的 jar 包中的位置|
|---|---|
|core-default.xml|hadoop-common-3.1.3.jar/core-default.xml|
|hdfs-default.xml|hadoop-hdfs-3.1.3.jar/hdfs-default.xml|
|yarn-default.xml|hadoop-yarn-common-3.1.3.jar/yarn-default.xml|
|mapred-default.xml|hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml|

#### 自定义配置文件
core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml
所有配置文件存放在 $HADOOP_HOME/etc/hadoop 这个路径上，用户可以根据项目需求重新进行修改配置:
1. hadoop-env.sh: Hadoop环境配置
2. xxx-site.xml: site 表示的是用户定义的配置，会覆盖 default 中的默认配置
   1. core-site.xml: 核心模块配置
   2. hdfs-site.xml: HDFS模块配置
   3. mapred-site.xml: MapReduce模块配置
   4. yarn-site.xml: YARN模块配置
3. workers: 工作结点配置

### 常用端口号
|端口名称|端口号|
|---|---|
|NameNode 内部通信端口|**8020**/9000/9820|
|NameNode HTTP UI|**9870**|
|MapReduce 查看执行任务端口|8088|
|历史服务器通信端口|19888|


## Hadoop配置

### 便捷脚本

#### 集群分发脚本
`xsync 文件路径`
```bash
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]; then
    echo Not Enough Arguement!
    exit 1
if

#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
    echo ==================== $host ====================

    #3. 遍历所有目录，挨个发送
    for file in $@
    do
        #4. 判断文件是否存在
        if [ -e $file ]
            then
                #5. 获取父目录
                pdir=$(cd -P $(dirname $file); pwd)

                #6. 获取当前文件的名称
                fname=$(basename $file)
                ssh $host "mkdir -p $pdir"
                rsync -av $pdir/$fname $host:$pdir
            else
                echo $file does not exists!
        fi
    done
done
```

#### 集群启停脚本
`myhadoop.sh start/stop`
```bash
#!/bin/bash
if [ $# -lt 1 ]
then
    echo "No Args Input..."
    exit 1
fi

case $1 in
"start")
    echo " =================== 启动 hadoop 集群 ==================="

    echo " --------------- 启动 hdfs ---------------"
    ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh"
    echo " --------------- 启动 yarn ---------------"
    ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh"
    echo " --------------- 启动 historyserver ---------------"
    ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"
;;
"stop")
    echo " =================== 关闭 hadoop 集群 ==================="
    
    echo " --------------- 关闭 historyserver ---------------"
    ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"
    echo " --------------- 关闭 yarn ---------------"
    ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"
    echo " --------------- 关闭 hdfs ---------------"
    ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"
;;
*)
    echo "Input Args Error..."
;;
esac
```

### 集群配置

#### core-site.xml
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 指定 NameNode 的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop102:8020</value>
    </property>

    <!-- 指定 hadoop 数据的存储目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
    </property>

    <!-- 配置 HDFS 网页登录使用的静态用户为 hadoop -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>hadoop</value>
    </property>
</configuration>
```

#### hdfs-site.xml
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- namenode web 端访问地址-->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop102:9870</value>
    </property>
    <!-- 2nn web 端访问地址-->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop104:9868</value>
    </property>
</configuration>
```

#### yarn-site.xml
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 指定 MR 走 shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>

    <!-- 指定 ResourceManager 的地址-->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop103</value>
    </property>
    
    <!-- 环境变量的继承 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
   </property>
</configuration>
```

#### mapred-site.xml
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- 指定 MapReduce 程序运行在 Yarn 上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
   </property>

   <!-- 是否将对容器实施物理内存限制，限制后: 如果任务超出分配值将被结束 -->
   <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
    </property>
    <!-- 是否将对容器实施虚拟内存限制，限制后: 如果任务超出分配值将被结束 -->
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
</configuration>
```

#### workers
```bash
vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
###### /opt/module/hadoop-3.1.3/etc/hadoop/workers ######
hadoop102
hadoop103
hadoop104
###### /opt/module/hadoop-3.1.3/etc/hadoop/workers ######
```

### NameNode格式化
如果集群是第一次启动，需要在格式化 NameNode。格式化 NameNode，会产生新的集群 id，导致 NameNode 和 DataNode 的集群 id 不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化 NameNode 的话，一定要先停止 namenode 和 datanode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化。

```bash
# NameNode所在节点
hdfs namenode -format
```

### 启动HDFS
```bash
# NameNode所在节点
sbin/start-dfs.sh
```

### 启动 YARN
```bash
# ResourceManager所在节点
sbin/start-yarn.sh
```

### 集群信息查看
* Web 端查看 HDFS 的 NameNode
  1. 浏览器中输入: http://hadoop102:9870
  2. 查看 HDFS 上存储的数据信息
* Web 端查看 YARN 的 ResourceManager
  1. 浏览器中输入: http://hadoop103:8088
  2. 查看 YARN 上运行的 Job 信息





## 日志聚集

### 定义
应用运行完成以后，将程序运行日志信息上传到 HDFS 系统上。可以方便的查看到程序运行详情，方便开发调试。

![运行环境搭建+20221110150436](https://raw.githubusercontent.com/loli0con/picgo/master/images/%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2B20221110150436.png%2B2022-11-10-15-04-36)

### 配置

#### 配置应用程序
修改mapred-site.xml，指定MR应用的历史服务器
```xml
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop102:10020</value>
</property>
<!-- 历史服务器 web 端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop102:19888</value>
</property>
```

#### 配置日志聚集
yarn-site.xml
```xml
<!-- 开启日志聚集功能 -->
<property>
    <name>yarn.log-aggregation-enable</name>
   <value>true</value>
</property>

<!-- 设置日志聚集服务器地址 -->
<property>
    <name>yarn.log.server.url</name>
    <value>http://hadoop102:19888/jobhistory/logs</value>
</property>

<!-- 设置日志保留时间为 7 天 -->
<property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>604800</value>
</property>
```

### 启动
```bash
# 在ResourceManager所在节点执行，重启NodeManager 、ResourceManage 和 HistoryServer
sbin/stop-yarn.sh
mapred --daemon stop historyserver
start-yarn.sh
mapred --daemon start historyserver
```

### 查看
http://hadoop102:19888/jobhistory





## 集群时间同步
如果服务器在公网环境(能连接外网)，可以不采用集群时间同步，因为服务器会定期和公网时间进行校准;如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，导致集群执行任务时间不同步。

todo